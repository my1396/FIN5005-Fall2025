{
  "hash": "c207bec535628348dbdb559ffe417dbc",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Regression with a Binary Dependent Variable\"\n---\n\n::: {.callout-note appearance=\"simple\" icon=false}\n🎯 **Study Objectives**\n\n- Understand why linear regression is inappropriate for binary dependent variables.\n- Learn the logit and probit models for analyzing binary outcomes.\n- Interpret coefficients in logistic regressions.\n- Apply logit/probit models using real-world data (HMDA mortgage application dataset).\n- Understand the concept of predicted probabilities.\n- Compare linear probability model (LPM), logit, and probit approaches.\n:::\n\n## Why Binary Dependent Variables Require Special Treatment\n\nIn many economic and financial applications, the dependent variable is **binary** (takes only two values: 0 or 1). Examples include:\n\n- **Mortgage approval**: Did the bank approve the mortgage application? (Yes = 1, No = 0)\n- **Labor force participation**: Is the individual employed? (Yes = 1, No = 0)\n- **Default risk**: Did the borrower default on the loan? (Yes = 1, No = 0)\n- **Market entry**: Does the firm enter the market? (Yes = 1, No = 0)\n- **Product choice**: Does the consumer purchase the product? (Yes = 1, No = 0)\n\n### Why Linear Regression Fails\n\nIf we try to use ordinary linear regression (OLS) with a binary dependent variable $Y_i \\in \\{0,1\\}$:\n\n$$\nY_i = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\cdots + \\beta_k X_{ki} + u_i\n$$\n\nThis approach is called the **Linear Probability Model (LPM)** because it estimates the probability that $Y_i = 1$ as a linear function of the predictors.\n\n**Problems with LPM:**\n\n1. **Predicted probabilities outside [0,1]**: OLS can produce fitted values $\\hat{Y}_i < 0$ or $\\hat{Y}_i > 1$, which makes no sense for probabilities.\n\n2. **Heteroskedasticity**: The error term variance depends on $X$, violating the homoskedasticity assumption. This means standard errors are incorrect.\n\n3. **Nonlinear relationship**: The effect of $X$ on the probability of $Y=1$ is unlikely to be constant across all values of $X$. \n   For example, increasing income from \\\\$20,000 to \\\\$30,000 likely has a different effect on mortgage approval than increasing from \\\\$200,000 to \\\\$210,000.\n\n### The Solution: Logit and Probit Models\n\nTo address these problems, we use **nonlinear models** that ensure predicted probabilities stay within [0,1]:\n\n- **Logit model**: Uses the logistic cumulative distribution function (CDF)\n- **Probit model**: Uses the standard normal cumulative distribution function (CDF)\n\n\n## The HMDA Dataset: Mortgage Lending Discrimination\n\nWe will use data from the **Federal Reserve Bank of Boston** collected under the **Home Mortgage Disclosure Act (HMDA)**. The dataset contains information on mortgage applications in the Boston area in 1990. The dataset contains 2380 observations with 14 variables.\n\n**Research Question:** Do banks discriminate against minority applicants when making mortgage lending decisions, after controlling for economic factors?\n\n### Load the Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required packages\npkgs <- c(\"AER\", \"tidyverse\", \"stargazer\", \"margins\", \"data.table\")\nmissing <- setdiff(pkgs, rownames(installed.packages()))\nif (length(missing) > 0) install.packages(missing)\ninvisible(lapply(pkgs, function(pkg) suppressPackageStartupMessages(library(pkg, character.only = TRUE))))\n\n# Load HMDA data\ndata(\"HMDA\")\n\n# Preview the data\ndata.table(HMDA)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        deny pirat hirat     lvrat  chist  mhist  phist unemp selfemp insurance\n      <fctr> <num> <num>     <num> <fctr> <fctr> <fctr> <num>  <fctr>    <fctr>\n   1:     no 0.221 0.221 0.8000000      5      2     no   3.9      no        no\n   2:     no 0.265 0.265 0.9218750      2      2     no   3.2      no        no\n   3:     no 0.372 0.248 0.9203980      1      2     no   3.2      no        no\n   4:     no 0.320 0.250 0.8604651      1      2     no   4.3      no        no\n   5:     no 0.360 0.350 0.6000000      1      1     no   3.2      no        no\n  ---                                                                          \n2376:     no 0.310 0.250 0.8000000      1      1     no   3.2     yes        no\n2377:     no 0.300 0.300 0.7770492      1      2     no   3.2      no        no\n2378:     no 0.260 0.200 0.5267606      2      1     no   3.1      no        no\n2379:    yes 0.320 0.260 0.7538462      6      1    yes   3.1      no        no\n2380:    yes 0.350 0.260 0.8135593      2      2     no   4.3      no        no\n      condomin   afam single hschool\n        <fctr> <fctr> <fctr>  <fctr>\n   1:       no     no     no     yes\n   2:       no     no    yes     yes\n   3:       no     no     no     yes\n   4:       no     no     no     yes\n   5:       no     no     no     yes\n  ---                               \n2376:       no     no     no     yes\n2377:      yes     no    yes     yes\n2378:       no     no     no     yes\n2379:      yes    yes    yes     yes\n2380:      yes     no    yes     yes\n```\n\n\n:::\n:::\n\n\n### Variable Definitions\n\nThe key variables in the HMDA dataset are:\n\n- We will mainly use `deny`, `pirat`, and `afam` in our analysis.\n\n| Variable | Definition |\n|----------|------------|\n| <span class=\"env-green\">`deny`</span> | Was the mortgage application denied? (yes/no) — **dependent variable** |\n| <span class=\"env-green\">`pirat`</span> | Payments-to-income ratio (monthly loan payments / monthly income) |\n| <span class=\"env-green\">`afam`</span> | Is the applicant African American? (yes/no) |\n| `hirat` | Housing expense-to-income ratio (monthly housing expenses / monthly income) |\n| `lvrat` | Loan-to-value ratio (loan amount / assessed property value) |\n| `chist` | Credit history: consumer credit score |\n| `mhist` | Mortgage history: mortgage credit score |\n| `phist` | Public record history: coded as \"no\" or \"yes\" (any bankruptcies, tax liens, etc.) |\n| `insurance` | Was mortgage insurance denied? (yes/no) |\n| `selfemp` | Is the applicant self-employed? (yes/no) |\n| `single` | Is the applicant single? (yes/no) |\n| `hschool` | Does the applicant have high school education? (yes/no) |\n| `unemp` | 1989 Massachusetts unemployment rate in applicant's industry (%). |\n| `condominium` | Is the property a condominium? (yes/no) |\n\n\n### Data Exploration\n\n#### Frequency Tables and Contingency Tables\n\n**Let's examine the denial rates overall and by race.**\n\nWe first look at the overall denial counts and rates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Overall denial counts\ncat(\"Overall Denial Counts:\\n\")\nwith(HMDA, table(deny))\n\n# Overall denial rate\ncat(\"===========================\\n\")\ncat(\"Overall Denial Rate:\\n\")\nwith(HMDA, prop.table(table(deny))) %>% round(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOverall Denial Counts:\ndeny\n  no  yes \n2095  285 \n===========================\nOverall Denial Rate:\ndeny\n  no  yes \n0.88 0.12 \n```\n\n\n:::\n:::\n\n\n\nThe table shows that about 12% of mortgage applications were denied overall. The majority of applications (88%) were approved.\n\nNext, we examine denial counts and rates by race.\n\n\nA <span class=\"env-green\">**contingency table**</span> is an effective method to see the association between two categorical variables. It counts the number of observations in each of the four possible scenarios.\nWhen dealing with just one categorical variable, this is referred to as a **frequency table**, which count the number of observations for each category.\n\nThe following gives a 2x2 contingency table for mortgage denial by African-American or not.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Denial rate by race\ncat(\"Denail counts by race:\\n\")\nwith(HMDA, table(deny, afam))\ncat(\"===========================\\n\")\ncat(\"Denial rate by race:\\n\")\nwith(HMDA, prop.table(table(deny, afam), margin = 2)) %>% round(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDenail counts by race:\n     afam\ndeny    no  yes\n  no  1852  243\n  yes  189   96\n===========================\nDenial rate by race:\n     afam\ndeny     no   yes\n  no  0.907 0.717\n  yes 0.093 0.283\n```\n\n\n:::\n:::\n\n\n\nSome observations from the table:\n\n- The majority of applicants are non-African American.\n- African American applicants have a higher denial rate (about 28%) compared to non-African American applicants (about 9%).\n\n:::{.callout-note appearance=\"simple\" icon=false}\nThis descriptive evidence suggests that *the likelihood of denial may be systematically higher for African American applicants*. However, these simple proportions do not control for other relevant factors such as income, credit history, or loan-to-value ratio. \nLogistic regression will allow us to model this relationship more rigorously while accounting for these additional variables.\n:::\n\n#### Summary Statistics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(HMDA)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  deny          pirat            hirat            lvrat        chist   \n no :2095   Min.   :0.0000   Min.   :0.0000   Min.   :0.0200   1:1353  \n yes: 285   1st Qu.:0.2800   1st Qu.:0.2140   1st Qu.:0.6527   2: 441  \n            Median :0.3300   Median :0.2600   Median :0.7795   3: 126  \n            Mean   :0.3308   Mean   :0.2553   Mean   :0.7378   4:  77  \n            3rd Qu.:0.3700   3rd Qu.:0.2988   3rd Qu.:0.8685   5: 182  \n            Max.   :3.0000   Max.   :3.0000   Max.   :1.9500   6: 201  \n mhist    phist          unemp        selfemp    insurance  condomin  \n 1: 747   no :2205   Min.   : 1.800   no :2103   no :2332   no :1694  \n 2:1571   yes: 175   1st Qu.: 3.100   yes: 277   yes:  48   yes: 686  \n 3:  41              Median : 3.200                                   \n 4:  21              Mean   : 3.774                                   \n                     3rd Qu.: 3.900                                   \n                     Max.   :10.600                                   \n  afam      single     hschool   \n no :2041   no :1444   no :  39  \n yes: 339   yes: 936   yes:2341  \n                                 \n                                 \n                                 \n                                 \n```\n\n\n:::\n:::\n\n\nSummary statistics by race.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Summary statistics by race\nHMDA %>%\n    group_by(afam) %>%\n    summarise(\n        n = n(),\n        denial_rate = mean(deny == \"yes\"),\n        mean_pirat = mean(pirat),\n        mean_lvrat = mean(lvrat)\n    )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  afam      n denial_rate mean_pirat mean_lvrat\n  <fct> <int>       <dbl>      <dbl>      <dbl>\n1 no     2041  0.09260167  0.3274625  0.7259712\n2 yes     339  0.2831858   0.3509891  0.8088478\n```\n\n\n:::\n:::\n\n\n### Visualizing the Contingency Table\n\nWe can visualize the contingency table using a **Stacked Bar Plot**.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_Logistic_Regression_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nThe stacked bar graph shows:\n\n- The sample sizes of African American and non-African American applicants\n- The distribution of approved vs. denied applications within each racial group\n- African American applicants appear to have a higher proportion of denials\n\n\nIssue: When the groups have very different sizes, it can be hard to compare proportions using absolute frequencies.\n\nRemedy: Use a **mosaic plot** to visualize **relative frequencies**.\n\n#### Mosaic Plot\n\nA mosaic plot replaces absolute frequencies with relative frequencies, making it easier to compare proportions across groups.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_Logistic_Regression_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n**Interpretation:**\n\n- The widths of the boxes are proportional to the percentage of each racial group in the sample.\n- The heights represent the denial rates within each group.\n- We can see that the \"Denied\" box for African American applicants is taller than for non-African American applicants, indicating a higher denial rate.\n\n### Measures of Risk and Association for Binary Outcomes\n\nTo quantify the difference in mortgage denial rates between racial groups, we can calculate several measures of risk and association.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate risk (denial rate) for each group\nrisk_table <- contingency_table %>%\n    prop.table(margin = 2) %>%\n    as.data.frame.matrix()\nrisk_table %>% round(3)\n# Extract probabilities\np_non_afam <- risk_table[\"Denied\", \"Non-African American\"] # P(deny=1 | afam=0)\np_afam <- risk_table[\"Denied\", \"African American\"] # P(deny=1 | afam=1)\n\ncat(\"\\nRisk (Denial Rate) by Race:\\n\")\ncat(\"===========================\\n\")\ncat(sprintf(\"Non-African American: %.4f (%.2f%%)\\n\", p_non_afam, p_non_afam * 100))\ncat(sprintf(\"African American:     %.4f (%.2f%%)\\n\", p_afam, p_afam * 100))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         Non-African American African American\nApproved                0.907            0.717\nDenied                  0.093            0.283\n\nRisk (Denial Rate) by Race:\n===========================\nNon-African American: 0.0926 (9.26%)\nAfrican American:     0.2832 (28.32%)\n```\n\n\n:::\n:::\n\n\n1. **Risk Difference (Excess Risk)**\n\n   The **risk difference** or **excess risk** (ER) is the difference in denial rates between the two groups:\n\n   $$\n   ER = P(\\text{deny}=1|\\text{afam}=1) - P(\\text{deny}=1|\\text{afam}=0)\n   $$\n\n\n   ::: {.cell}\n   \n   ```{.r .cell-code}\n   ER <- p_afam - p_non_afam\n   cat(\"\\nRisk Difference (Excess Risk):\\n\")\n   cat(\"==============================\\n\")\n   cat(sprintf(\"ER = %.4f - %.4f = %.4f (%.2f percentage points)\\n\", p_afam, p_non_afam, ER, ER * 100))\n   ```\n   \n   ::: {.cell-output .cell-output-stdout}\n   \n   ```\n   \n   Risk Difference (Excess Risk):\n   ==============================\n   ER = 0.2832 - 0.0926 = 0.1906 (19.06 percentage points)\n   ```\n   \n   \n   :::\n   :::\n\n\n   **Interpretation:** African American applicants have a denial rate that is 19.06 percentage points higher than non-African American applicants.\n\n   - If $ER = 0$: no difference in risk between groups\n   - If $ER > 0$: higher risk for the <span class=\"env-green\">treatment group</span> (African Americans, `afam=1`)\n     \n     By contrast, the <span class=\"env-green\">control group</span> is non-African Americans (`afam=0`).\n   - If $ER < 0$: lower risk for the treatment group\n\n2. **Risk Ratio (Relative Risk)**\n\n   The **risk ratio** or **relative risk** (RR) is the ratio of denial rates:\n\n   $$\n   RR = \\frac{P(\\text{deny}=1|\\text{afam}=1)}{P(\\text{deny}=1|\\text{afam}=0)}\n   $$\n\n\n   ::: {.cell}\n   \n   ```{.r .cell-code}\n   RR <- p_afam / p_non_afam\n   cat(\"\\nRisk Ratio (Relative Risk):\\n\")\n   cat(\"===========================\\n\")\n   cat(sprintf(\"RR = %.4f / %.4f = %.4f\\n\", p_afam, p_non_afam, RR))\n   ```\n   \n   ::: {.cell-output .cell-output-stdout}\n   \n   ```\n   \n   Risk Ratio (Relative Risk):\n   ===========================\n   RR = 0.2832 / 0.0926 = 3.0581\n   ```\n   \n   \n   :::\n   :::\n\n\n   **Interpretation:** African American applicants have a denial rate that is 3.06 times higher than non-African American applicants.\n\n   - If $RR = 1$: no difference in risk\n   - If $RR > 1$: higher risk for the treatment group (African Americans, `afam=1`)\n   - If $RR < 1$: lower risk for the treatment group\n\n3. **Odds Ratio**\n\n   The **odds ratio** (OR) compares the odds of denial between the two groups.\n\n   First, calculate the odds for each group:\n\n   $$\n   \\text{odds} = \\frac{P(\\text{deny}=1)}{P(\\text{deny}=0)} = \\frac{P(\\text{deny}=1)}{1 - P(\\text{deny}=1)}\n   $$\n\n\n   ::: {.cell}\n   \n   ```{.r .cell-code}\n   # Calculate odds for each group\n   odds_non_afam <- p_non_afam / (1 - p_non_afam)\n   odds_afam <- p_afam / (1 - p_afam)\n   \n   cat(\"\\nOdds by Race:\\n\")\n   cat(\"=============\\n\")\n   cat(sprintf(\"Non-African American: %.4f\\n\", odds_non_afam))\n   cat(sprintf(\"African American:     %.4f\\n\", odds_afam))\n   ```\n   \n   ::: {.cell-output .cell-output-stdout}\n   \n   ```\n   \n   Odds by Race:\n   =============\n   Non-African American: 0.1021\n   African American:     0.3951\n   ```\n   \n   \n   :::\n   :::\n\n   \n   This means that the odds of being denied a mortgage are approximately **0.10 for non--African American applicants** and **0.40 for African American applicants**.\n   \n   The <span class=\"env-green\">**odds ratio**</span> is:\n\n   $$\n   OR = \\frac{\\text{odds}(\\text{afam}=1)}{\\text{odds}(\\text{afam}=0)} = \\frac{P(\\text{deny}=1|\\text{afam}=1)/[1-P(\\text{deny}=1|\\text{afam}=1)]}{P(\\text{deny}=1|\\text{afam}=0)/[1-P(\\text{deny}=1|\\text{afam}=0)]}\n   $$\n\n\n   ::: {.cell}\n   \n   ```{.r .cell-code}\n   OR <- odds_afam / odds_non_afam\n   cat(\"\\nOdds Ratio:\\n\")\n   cat(\"===========\\n\")\n   cat(sprintf(\"OR = %.4f/%.4f = %.4f\\n\", odds_afam, odds_non_afam, OR))\n   ```\n   \n   ::: {.cell-output .cell-output-stdout}\n   \n   ```\n   \n   Odds Ratio:\n   ===========\n   OR = 0.3951/0.1021 = 3.8712\n   ```\n   \n   \n   :::\n   :::\n\n\n   **Interpretation:** The odds of mortgage denial for African American applicants are 3.87 times higher than the odds for non-African American applicants.\n\n   - If $OR = 1$: no difference in odds\n   - If $OR > 1$: higher odds for the treatment group (African Americans, `afam=1`)\n   - If $OR < 1$: lower odds for the treatment group\n\n:::{.callout-note}\n## Important Distinction\n\n- **Risk difference** measures the absolute difference in probabilities (additive scale)\n- **Risk ratio** and **odds ratio** measure relative differences (multiplicative scale)\n- The odds ratio is particularly useful because <span class=\"env-green\">it directly relates to the coefficient in logistic regression</span>: \n  \n  When we estimate a logistic model with `afam` as the predictor, $e^{\\beta_{\\text{afam}}}$ will approximately equal the odds ratio we calculated here.\n:::\n\n## Model Specification: The Boston Mortgage Example\n\nWe want to model the probability that a mortgage application is denied as a function of applicant characteristics.\n\n### Preparing the Data\n\nFirst, we create a binary numeric variable for denial (1 = denied, 0 = approved) and recode some factors:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create binary dependent variable\nHMDA$deny_binary <- ifelse(HMDA$deny == \"yes\", 1, 0)\n\n# Create binary variable for African American\nHMDA$afam_binary <- ifelse(HMDA$afam == \"yes\", 1, 0)\n\n# Check the variables\nhead(HMDA[, c(\"deny\", \"deny_binary\", \"pirat\", \"afam\", \"afam_binary\")])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  deny deny_binary pirat afam afam_binary\n1   no           0 0.221   no           0\n2   no           0 0.265   no           0\n3   no           0 0.372   no           0\n4   no           0 0.320   no           0\n5   no           0 0.360   no           0\n6   no           0 0.240   no           0\n```\n\n\n:::\n:::\n\n\n### Model 1: Linear Probability Model\n\nLet's start with a simple linear regression to see its limitations.\n\nThe OLS regression of the binary dependent variable, $deny$ against the payment-to-income ratio (`pirat`), is estimated as:\n\n$$\ndeny = \\beta_0 + \\beta_1 \\cdot pirat + \\varepsilon\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlpm_simple <- lm(deny_binary ~ pirat, data = HMDA)\ncoeftest(lpm_simple, vcov. = vcovHC, type = \"HC1\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nt test of coefficients:\n\n             Estimate Std. Error t value  Pr(>|t|)    \n(Intercept) -0.079910   0.031967 -2.4998   0.01249 *  \npirat        0.603535   0.098483  6.1283 1.036e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n$$\n\\widehat{deny} = -0.080 + 0.604 \\cdot pirat\n$$\n\nThe estimated coefficient on P/I ratio is positive, and the population coefficient is statistically significantly different from 0 at the 1% level (the t-statistic is 6.12). \nIf P/I ratio increases by 0.1, the probability of denial increases by approximately $0.604\\times 0.1 \\approx 0.060,$ that is, by 6 percentage points.\nThus applicants with higher debt payments as a fraction of income are more likely to have their application denied.\n\nNow we plot the data and the regression line to visualize the model.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_Logistic_Regression_files/figure-html/fig-linear-1.png){#fig-linear width=672}\n:::\n:::\n\n\n::: {.callout-warning title=\"Shortcomings with the linear probability model\" icon=\"false\"}\n\n1. The linear probability model can predict probabilities outside the $[0,1]$ range. For example, for high values of P/I ratio (`pirat`), the predicted probability exceeds 1. However, probabilities must lie between 0 and 1.\n2. The relationship between P/I ratio and the probability of denial may NOT be linear in reality. \n   \n   It is reasonable to expect the marginal effects of P/I ratio on denial probability to diminish as P/I ratio increases. \n   \n   Although a change in P/I ratio from 0.3 to 0.4 might have a large effect on the probability of denial, once the P/I ratio is already very high (e.g., 0.9 to 1.0), increasing P/I ratio further will have litte effect.\n3. The error term in the linear probability model is *heteroskedastic*, violating OLS assumptions. \n   \n   This means that standard errors and hypothesis tests based on OLS are invalid. → This issue can be addressed using heteroskedasticity robust standard errors.\n:::\n\n### Model 2: Logit Regression with a single predictor\n\nThe estimated model is \n$$\n\\mathrm P(deny_i = 1 | pirat_i) = F(\\beta_0 + \\beta_1 \\cdot pirat_i) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 \\cdot pirat_i)}} ,\n$$\n\nwhere $F$ is the logistic distribution function.\n\nNote that the left-hand side is the probability that the $i$-th mortgage application is denied ($deny_i = 1$), given the payment-to-income ratio ($pirat_i$).\n\nThe strength of the logit model is that <span class=\"env-green\">it ensures predicted probabilities are always between 0 and 1</span>.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Estimate logit model\nlogit_simple <- glm(deny_binary ~ pirat,\n    family = binomial(link = \"logit\"),\n    data = HMDA\n)\ncoeftest(logit_simple, vcov. = vcovHC, type = \"HC1\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nz test of coefficients:\n\n            Estimate Std. Error  z value  Pr(>|z|)    \n(Intercept) -4.02843    0.35898 -11.2218 < 2.2e-16 ***\npirat        5.88450    1.00015   5.8836 4.014e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n$$\n\\widehat{\\mathrm P}(deny_i = 1 | pirat_i) = F(-4.02 + 5.88 \\cdot pirat_i)= \\frac{1}{1 + e^{-(-4.02 + 5.88 \\cdot pirat_i)}}\n$$\n\nVisualizing the logit model:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![The logit model uses the logistic distribution function to model the probability of denial as a function of the payment-to-income ratio. Unlike the linear probability model, the logit model ensures predicted probabilities remain within the [0,1] range.](09_Logistic_Regression_files/figure-html/fig-logit-1.png){#fig-logit width=672}\n:::\n:::\n\n\nThe estimated logit regression function has a stretched “S” shape: It is nearly 0 and flat for small values of P/I ratio, it turns and increases for intermediate values, and it flattens out again and is nearly 1 for large values. \n\n::: {.example #exm-1}\n**Predicted probability.**\n\nWhat is the probability of denial given a P/I ratio of 0.3? What about for P/I ratio being 0.4 and 0.5?\n:::\n\n<button class=\"solution-btn\" onclick=\"myFunction('sol-1')\">Solution</button>\n<div id=\"sol-1\" class=\"solution-answer env-green\">\nFor P/I ratio of 0.3, the estimated probability of denial based on the estimated logit model is:\n$$\n\\widehat{P}(deny = 1 | pirat = 0.3) = \\frac{1}{1 + e^{-(-4.02 + 5.88 \\cdot 0.3)}} \\approx 9.4\\%\n$$\nThat is, the probability of denial is approximately 9.4%.\n\nFor P/I ratio of 0.4:\n$$\n\\widehat{P}(deny = 1 | pirat = 0.4) = \\frac{1}{1 + e^{-(-4.02 + 5.88 \\cdot 0.4)}} \\approx 15.7\\%\n$$\nThat is, the probability of denial is approximately 15.7%.\n\nFor P/I ratio of 0.5:\n$$\n\\widehat{P}(deny = 1 | pirat = 0.5) = \\frac{1}{1 + e^{-(-4.02 + 5.88 \\cdot 0.5)}} \\approx 25.2\\%\n$$\n\n**Main takeaway:** As P/I ratio increases, the probability of denial increases, but not linearly.\n</div>\n\n\n<span class=\"env-green\">**Interpretation on the logit coefficients:**</span>\n\nThe estimated model is\n\n$$\n\\widehat{P}(deny_i = 1 \\mid pirat_i) = \\frac{1}{1 + e^{-(-4.02 + 5.88 \\cdot pirat_i)}}\n$$\n\nwhich can be written in **log-odds form** as\n\n$$\n\\log\\left(\\frac{P(deny_i = 1)}{1 - P(deny_i = 1)}\\right) = -4.02 + 5.88 \\cdot pirat_i\n$$\n\n1. **Interpreting coefficients (log-odds scale):**\n   \n   The slope coefficient, $\\hat{\\beta}_1 = 5.88$, means that a **one-unit increase** in `pirat` increases the **log-odds** of mortgage denial by **5.88**, holding all else constant. \n\n2. **Interpreting odds ratios (exponentiating coefficients):**\n\n   To obtain a more intuitive interpretation, we exponentiate the coefficient:\n   $$\n   e^{\\hat{\\beta}_1} = e^{5.88} \\approx 357.7\n   $$\n   This means that for a **one-unit increase** in the payment-to-income ratio, the **odds** of mortgage denial are about **357.7 times larger**.\n   \n   - Because a one-unit increase in `pirat` is very large in practice, it is often more meaningful to interpret smaller changes.\n \n   For example, for a **0.1 increase** in `pirat`:\n   $$\n   e^{5.88 \\times 0.1} \\approx 1.80\n   $$\n   This means that a 0.1 increase in the payment-to-income ratio increases the **odds of denial by about 80%**.\n\n**Hypothesis Testing:**\n\nUsing the normal distribution of parameter estimates, we can use the standard normal table rather than the $t$ table for critical points to test hypotheses about the coefficients.\n\nThe $z$-statistic for testing $H_0: \\beta_1 = 0$ is:\n\n$$\nz = \\frac{\\hat{\\beta}_1 - 0}{SE(\\hat{\\beta}_1)} = \\frac{5.88 - 0}{1} \\approx 5.88\n$$\n\nSince $z > 1.96$, we reject the null hypothesis at the 5% significance level and conclude that there is a statistically significant positive relationship between payment-to-income ratio and the probability of mortgage denial.\n\n### Model 3: Linear Probability Model with Multiple Predictors\n$$\ndeny_i = \\beta_0 + \\beta_1 \\cdot pirat_i + \\beta_2 \\cdot afam_i\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Estimate LPM\nlpm_multi <- lm(deny_binary ~ pirat + afam_binary, data = HMDA)\nsummary(lpm_multi)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = deny_binary ~ pirat + afam_binary, data = HMDA)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.62526 -0.11772 -0.09293 -0.05488  1.06815 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.09051    0.02079  -4.354 1.39e-05 ***\npirat        0.55919    0.05987   9.340  < 2e-16 ***\nafam_binary  0.17743    0.01837   9.659  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3123 on 2377 degrees of freedom\nMultiple R-squared:  0.076,\tAdjusted R-squared:  0.07523 \nF-statistic: 97.76 on 2 and 2377 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n**Interpretation:**\n\n- $\\hat{\\beta}_1$: A one-unit increase in the payment-to-income ratio increases the probability of denial by approximately $\\hat{\\beta}_1$.\n- $\\hat{\\beta}_2$: African American applicants have a probability of denial that is $\\hat{\\beta}_2$ percentage points higher than non-African American applicants, holding `pirat` constant.\n\n### Model 4: Logit Model with Multiple Predictors\n\nNow we estimate a logit model including both P/I ratio (`pirat`) and African-American binary (`afam_binary`) as predictors:\n\n$$\nP(deny_i = 1 | pirat_i, afam_i) = F(\\beta_0 + \\beta_1 \\cdot pirat_i + \\beta_2 \\cdot afam_i) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 \\cdot pirat_i + \\beta_2 \\cdot afam_i)}} .\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Estimate logit model\nlogit_multi <- glm(deny_binary ~ pirat + afam_binary,\n    family = binomial(link = \"logit\"),\n    data = HMDA\n)\ncoeftest(logit_multi, vcov. = vcovHC, type = \"HC1\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nz test of coefficients:\n\n            Estimate Std. Error  z value  Pr(>|z|)    \n(Intercept) -4.12556    0.34597 -11.9245 < 2.2e-16 ***\npirat        5.37036    0.96376   5.5723 2.514e-08 ***\nafam_binary  1.27278    0.14616   8.7081 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\nThe estimated logit model is:\n$$\n\\begin{split}\n\\widehat{P}(deny_i = 1 | pirat_i, afam_i) &= F(-4.13 + 5.37 \\cdot pirat_i + 1.27 \\cdot afam_i) \\\\\n&= \\frac{1}{1 + e^{-(-4.13 + 5.37 \\cdot pirat_i + 1.27 \\cdot afam_i)}}\n\\end{split}\n$$\n\n<span class=\"env-green\">**Interpretation of Logit Coefficients**</span>\n\nThe coefficients in a logit model represent the change in the **log-odds** of denial:\n\n$$\n\\log\\left(\\frac{P(deny = 1)}{1 - P(deny = 1)}\\right) = -4.13 + 5.37 \\cdot pirat_i + 1.27 \\cdot afam_i\n$$\n\n**1. Interpreting coefficients (log-odds scale):**\n\n- $\\hat{\\beta}_1 > 0$: A one-unit increase in `pirat` increases the log-odds of denial by $\\hat{\\beta}_1$, holding other variables constant.\n- $\\hat{\\beta}_2 > 0$: Being African American increases the log-odds of denial by $\\hat{\\beta}_2$ compared to non-African Americans, holding other variables constant.\n\n**2. Interpreting odds ratios (exponentiating coefficients):**\n\nAlternatively, we can interpret the **odds ratio** by taking the exponential of the coefficients:\n\n\n\n- **For `pirat`**: $e^{\\hat{\\beta}_1}$ represents the **multiplicative change in odds** for a one-unit increase in the payment-to-income ratio. \n  \n  For example, if the P/I ratio increases by 0.2, then $e^{5.37\\times 0.2} = 2.93$, that is, the odds of mortgage denial are approximately 2.94 times higher, holding `afam` constant.\n\n- **For `afam`**: $e^{\\hat{\\beta}_2}$ is the **odds ratio comparing African American applicants to non-African American applicants**.\n  \n  Based on the estimates, $e^{1.2} = 3.56$, that is, African American applicants have odds of denial that are 3.56 times higher than non-African American applicants, holding `pirat` constant.\n\n::: {.example #exm-2}\n\nSuppose we have:\n\n- Odds of denial for a non-African American applicant with `pirat = 0.3` is 0.15\n- The odds ratio for African Americans compared to non-African American is $e^{\\hat{\\beta}_2} = 3.56$\n\nCalculate the expected odds for an African American applicant with the same `pirat = 0.3`.\n:::\n\n<button class=\"solution-btn\" onclick=\"myFunction('sol-2')\">Solution</button>\n::: {#sol-2 .solution-answer .env-green}\n$$\n\\text{odds}(\\text{afam}=1) = \\text{odds}(\\text{afam}=0) \\times e^{\\hat{\\beta}_2} = 0.15 \\times 3.56 = 0.534\n$$\nThe expected odds of denial for an African American applicant with `pirat = 0.3` is 0.534.\n:::\n\n\n### Model 5: Probit Model\n\nIn contrast to the logit model, which uses the logistic CDF, the probit model uses the <span class=\"env-green\">standard normal</span> distribution function to model the probability of denial.\n$$\nP(deny_i = 1 | X_i) = \\Phi(\\beta_0 + \\beta_1 \\cdot pirat_i + \\beta_2 \\cdot afam_i)\n$$\n\nwhere $\\Phi(\\cdot)$ is the standard normal CDF.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Estimate probit model\nprobit_multi <- glm(deny_binary ~ pirat + afam_binary,\n    family = binomial(link = \"probit\"),\n    data = HMDA\n)\ncoeftest(probit_multi, vcov. = vcovHC, type = \"HC1\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nz test of coefficients:\n\n             Estimate Std. Error  z value  Pr(>|z|)    \n(Intercept) -2.258787   0.176608 -12.7898 < 2.2e-16 ***\npirat        2.741779   0.497673   5.5092 3.605e-08 ***\nafam_binary  0.708155   0.083091   8.5227 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n### Comparison: Logit, and Probit\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_Logistic_Regression_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n**Practical Recommendation:**\n\n- Logit and probit typically give very similar results.\n- Logit is more common in economics and finance due to the convenient odds ratio interpretation.\n\n### Predicted Probabilities\n\nTo compare effects across models, we calculate **predicted probabilities** at specific values of the predictors.\n\n::: {.example #exm-3}\nFor the three multivariate models (models 3–5), what is the predicted probability of denial for:\n\n- An African American applicant with `pirat = 0.3`?\n- A non-African American applicant with `pirat = 0.3`?\n:::\n\n<button class=\"solution-btn\" onclick=\"myFunction('sol-3')\">Solution</button>\n::: {#sol-3 .solution-answer .env-green}\n&nbsp;\n\n**For linear probability model (LPM):**\n\n- African American applicant (`afam_binary = 1`):\n  $$\n  \\widehat{deny} = -0.09 + 0.56 \\times 0.3 + 0.18 \\times 1 = 0.258 \n  $$\n- Non-African American applicant (`afam_binary = 0`):\n  $$\n  \\widehat{deny} = -0.09 + 0.56 \\times 0.3 + 0.18 \\times 0 = 0.078\n  $$\n\n**For logit model:**\n\n- African American applicant:\n  $$\n  \\widehat{P}(deny = 1 | pirat = 0.3, afam = 1) = \\frac{1}{1 + e^{-(-4.13 + 5.37 \\times 0.3 + 1.27 \\times 1)}} \\approx 0.22\n  $$\n- Non-African American applicant:\n  $$\n  \\widehat{P}(deny = 1 | pirat = 0.3, afam = 1) = \\frac{1}{1 + e^{-(-4.13 + 5.37 \\times 0.3 + 1.27 \\times 0)}} \\approx 0.07\n  $$\n\n**For probit model:**\n\n- African American applicant:\n  $$\n  \\widehat{P}(deny = 1 | pirat = 0.3, afam = 1) = \\Phi(-2.26 + 2.74 \\times 0.3 + 0.71 \\times 1) = \\Phi(-0.728)\n  $$\n  Refer to the standard normal table for $\\Phi(-0.728) \\approx 0.23$.\n- Non-African American applicant:\n  $$\n  \\widehat{P}(deny = 1 | pirat = 0.3, afam = 0) = \\Phi(-2.26 + 2.74 \\times 0.3 + 0.71 \\times 0) \\approx 0.075\n  $$\n  Refer to the standard normal table for $\\Phi(-1.438) \\approx 0.075$.\n:::\n\n\n\n\n\n## Summary: Logit vs. Probit vs. LPM\n\n|  | Linear | Logit | Probit |\n|---------|-----|-------|--------|\n| **Function** | Linear | Logistic CDF | Normal CDF |\n| **Predicted probabilities** | Can be outside [0,1] | Always in [0,1] | Always in [0,1] |\n| **Interpretation** | Direct (probability) | Log-odds / Odds ratio | Z-score |\n| **Heteroskedasticity** | Always present | Accounted for | Accounted for |\n| **When to use** | Quick approximation | Preferred for most applications | Similar to logit; standard in some fields |\n\n\n\n",
    "supporting": [
      "09_Logistic_Regression_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}