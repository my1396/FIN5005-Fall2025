{
  "hash": "00bde133fcbd3a4f7b490a38572e466a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Interactions of Binary Variables\"\n---\n\n::: {.callout-note appearance=\"simple\" icon=false}\nðŸŽ¯ **Study Objectives**\n\n- Interpret interaction terms of two binary variables in regression models.\n- Understand the importance of controlling for changes in interacting variables when interpreting coefficients.\n- Conduct and interpret a two-way ANOVA to compare nested regression models.\n- Interpret interaction terms between a binary variable and a continuous variable in regression models.\n- Visualize interaction effects using regression lines.\n:::\n\nFor this section of the course, we will be working with the `Boston` dataset, which contains 506 observations on housing values in various suburbs of Boston. This dataset provides detailed information on factors such as crime rates, property age, locations (proximity to the Charles River), and other socioeconomic variables. \n\nWe will use this data to **explore and analyze the determinants of housing prices**, applying regression techniques to understand how different factors influence the value of homes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load packages and dataset\npkgs <- c(\"tidyverse\", \"MASS\", \"data.table\", \"stargazer\", \"cowplot\")\nmissing <- setdiff(pkgs, rownames(installed.packages()))\nif (length(missing) > 0) install.packages(missing)\ninvisible(lapply(pkgs, function(pkg) suppressPackageStartupMessages(library(pkg, character.only = TRUE))))\ndata(Boston) # Boston housing data\n```\n:::\n\n\nUse `?Boston` to see the description of the dataset.\n\nHere are some variables in the dataset which we are going to use in this session.\n\n| Variables | Definitions                                                  |\n| --------- | ------------------------------------------------------------ |\n| `medv`    | median value of owner-occupied homes in \\$1000s.             |\n| `lstat`   | the percentage of individuals with low socioeconomic status  |\n| `indus`   | proportion of non-retail business acres per town; industrial, office, or commercial land not directly serving consumers.            |\n| `age`     | proportion of owner-occupied units built prior to 1940.      |\n| `crim`    | per capita crime rate by town.                               |\n| `chas`    | A dummy variable. Takes the value 1 if the Charles River (a short river in the proximity of Boston) passes through the suburb and is 0 otherwise. |\n\n## Interactions of Two Binary Variables\n\nConsider the following regression model\n\n$$\nmedv_i = \\beta_0 + \\beta_1\\, chas_i + \\beta_2\\, old_i + \\beta_3\\, (chas_i \\times old_i) + u_i\n$$ {#eq-binary-interaction}\n\nwhere $chas_i$ and $old_i$ are dummy variables defined as follows:\n\n$$\n\\begin{aligned}\nchas_i &= \\begin{cases}\n1 & \\text{if the suburb is next to the Charles River} \\\\\n0 & \\text{otherwise}\n\\end{cases} \\\\\nold_i &= \\begin{cases}\n1 & \\text{if } age_i \\ge 95 \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\end{aligned}\n$$\n\nwhere $agi_i$ being the proportion of owner-occupied units built prior to 1940.\n\n**Instructions:**\n\n- Generate and append the binary variable $old$ to the dataset Boston.\n- Conduct the regression stated above and assign the result to `mod_bb`.\n- Obtain a robust coefficient summary of the model. How do you interpret the results?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nBoston <- Boston %>%\n    mutate(old = ifelse(age >= 95, 1, 0))\nmod_bb <- lm(medv ~ chas*old, data = Boston)\nsummary(mod_bb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = medv ~ chas * old, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-17.771  -4.765  -1.683   2.776  33.433 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  23.6989     0.4503  52.624  < 2e-16 ***\nchas          4.0582     1.6872   2.405   0.0165 *  \nold          -7.1319     0.9493  -7.513 2.67e-13 ***\nchas:old     10.5462     3.7577   2.807   0.0052 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.604 on 502 degrees of freedom\nMultiple R-squared:  0.1301,\tAdjusted R-squared:  0.1249 \nF-statistic: 25.02 on 3 and 502 DF,  p-value: 4.244e-15\n```\n\n\n:::\n:::\n\n\nThe estimated regression model is given by\n\n$$\n\\widehat{medv}_i = 23.70 + 4.06\\, chas_i - 7.13\\, old_i + 10.55\\, (chas_i \\times old_i)\n$$\n\n<span class=\"env-green\">**Interpretation of the coefficients**</span>\n\nWe start with listing all possible combinations of the binary variables $chas_i$ and $old_i$.\n\n| Scenario | $chas_i$ | $old_i$ | Interpretation                                      |\n| --- | -------- | ------- | --------------------------------------------------- |\n| **1** | 0        | 0       | Suburb not next to Charles River and new |\n| **2** | 0        | 1       | Suburb not next to Charles River and old |\n| **3** | 1        | 0       | Suburb next to Charles River and new     |\n| **4** | 1        | 1       | Suburb next to Charles River and old     |\n\n\nBased on the estimated regression model, we can compute the expected value of `medv` for each of the four groups.\n\n| Scenario | $chas_i$ | $old_i$ | $chas_i \\times old_i$ | Expected value of `medv`                                                                 |\n|:--------:|:--------:|:-------:|:---------------------:|:-----------------------------------------------------------------------------------------|\n|  **1**   |    0     |    0    |          0            | $\\color{#0099FF}{\\hat{\\beta}_0} = 23.70$                                                                  |\n|  **2**   |    0     |    1    |          0            | ${\\color{#0099FF}\\hat{\\beta}_0} + {\\color{#00CC66}\\hat{\\beta}_2} = {\\color{#0099FF}23.70} + {\\color{#00CC66}(- 7.13)} = 16.57$                |\n|  **3**   |    1     |    0    |          0            | ${\\color{#0099FF}\\hat{\\beta}_0} + {\\color{#fb5b89}\\hat{\\beta}_1} = {\\color{#0099FF}23.70} + {\\color{#fb5b89}4.06} = 27.76$                  |\n|  **4**   |    1     |    1    |          1            | ${\\color{#0099FF}\\hat{\\beta}_0} + {\\color{#fb5b89}\\hat{\\beta}_1} + {\\color{#00CC66}\\hat{\\beta}_2} + {\\color{orange}\\hat{\\beta}_3} = {\\color{#0099FF}23.70} + {\\color{#fb5b89}4.06} + {\\color{#00CC66}(-7.13)} + {\\color{orange}(10.55)} = 31.18$ |\n\n\nFrom the table above, we can interpret the coefficients as follows:\n\n- $\\color{#0099FF}{\\hat{\\beta}_0} = 23.70$ is the expected value of `medv` for suburbs that are not next to the Charles River and are new (i.e., `old = 0`).\n\n- Comparing scenario 2 with 1: $\\color{#00CC66}{\\hat{\\beta}_2} = -7.13$ is the difference in expected value of `medv` between new and old suburbs that are **NOT next to the Charles River**. \n  \n  In other words, old suburbs that are not next to the Charles River have an expected `medv` that is 7.13 lower than new suburbs that are **NOT next to the Charles River**.\n\n- Comparing scenario 3 with 1: $\\color{#fb5b89}{\\hat{\\beta}_1} = 4.06$ is the difference in expected value of `medv` between suburbs that are next to the Charles River and those that are not, among **new** suburbs (i.e., `old = 0`). \n  \n  In other words, **new** suburbs that are next to the Charles River have an expected `medv` that is 4.06 higher than new suburbs that are not next to the Charles River.\n\n- $\\color{orange}{\\hat{\\beta}_3} = 10.55$ has two interpretations:\n  - If we compare scenario 4 with scenario 2, the difference in expected value of `medv` is given by ${\\color{#fb5b89}\\hat{\\beta}_1} + {\\color{orange}\\hat{\\beta}_3} = 4.06 + 10.55 = 14.61.$ \n    \n    This means that **old** suburbs that are next to the Charles River have an expected `medv` that is 14.61 higher than **old** suburbs that are not next to the Charles River. \n\n    â†’ $\\color{orange}{\\hat{\\beta}_3}$ can be interpreted as the difference in the effect of being next to the Charles River between old and new suburbs.\n\n  - If we compare scenario 4 with scenario 3, the difference in expected value of `medv` is given by ${\\color{#00CC66}\\hat{\\beta}_2} + {\\color{orange}\\hat{\\beta}_3} = -7.13 + 10.55 = 3.42.$\n    \n    This means that old suburbs that are **next to the Charles River** have an expected `medv` that is 3.42 higher than new suburbs that are **next to the Charles River**.\n\n    â†’ $\\color{orange}{\\hat{\\beta}_3}$ can be interpreted as the difference in the effect of being old between suburbs that are next to the Charles River and those that are not.\n\n\n:::{.callout-tip}\n<span class=\"env-green\">**Controlling for changes in the interacting variables**</span> is essential when interpreting the coefficient of interaction terms. \n\nA common approach is to substitute specific values for the interacting variables and compute the expected value of the dependent variable under different scenarios. This allows for a clearer interpretation of the coefficients by comparing how the expected value of the dependent variable varies across these scenarios.\n:::\n\n### Add More Controls Variables\n\nWe can also add more control variables to @eq-binary-interaction to improve the model fit (Adjusted $R^2 = 12\\%$ as of now). For example, we can add `lstat` and `crim` as additional control variables.\n\n$$\nmedv_i = \\beta_0 + \\beta_1\\, chas_i + \\beta_2\\, old_i + \\beta_3\\, (chas_i \\times old_i) + \\beta_4\\, lstat_i + \\beta_5\\, crim_i + u_i\n$$ {#eq-binary-interaction-more-controls}\n\nWe estimate the above regression model as follows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_bb2 <- lm(medv ~ chas*old + lstat + crim, data = Boston)\nstargazer(mod_bb, mod_bb2, type=\"text\", \n    column.labels = c(\"Restricted\", \"Unrestricted\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n====================================================================\n                                  Dependent variable:               \n                    ------------------------------------------------\n                                          medv                      \n                          Restricted              Unrestricted      \n                              (1)                     (2)           \n--------------------------------------------------------------------\nchas                        4.058**                 4.000***        \n                            (1.687)                 (1.183)         \n                                                                    \nold                        -7.132***                1.748**         \n                            (0.949)                 (0.776)         \n                                                                    \nlstat                                              -0.949***        \n                                                    (0.046)         \n                                                                    \ncrim                                                -0.079**        \n                                                    (0.036)         \n                                                                    \nchas:old                   10.546***                 4.008          \n                            (3.758)                 (2.651)         \n                                                                    \nConstant                   23.699***               34.106***        \n                            (0.450)                 (0.573)         \n                                                                    \n--------------------------------------------------------------------\nObservations                  506                     506           \nR2                           0.130                   0.574          \nAdjusted R2                  0.125                   0.570          \nResidual Std. Error    8.604 (df = 502)         6.033 (df = 500)    \nF Statistic         25.017*** (df = 3; 502) 134.705*** (df = 5; 500)\n====================================================================\nNote:                                    *p<0.1; **p<0.05; ***p<0.01\n```\n\n\n:::\n:::\n\n\n\n**Comparing the two models:**\n\n- The coefficient of `old` reversed signs, from negative ($-7.13$) to positive ($1.75$), suggesting that after accounting for crime and low socioeconomic status, older suburbs have slightly higher values.\n- Negative coefficients for `lstat` ($-0.95$) and `crim` ($-0.079$) indicate that higher poverty and crime reduce house values.\n\n\nPlot `lstat` and `crim` group by `old` to see how the distribution of these two variables differ between new and old suburbs.\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- ggplot(Boston, aes(x = factor(old), y = lstat)) +\n    geom_boxplot(fill = \"lightblue\")\np2 <- ggplot(Boston, aes(x = factor(old), y = crim)) +\n    geom_boxplot(fill = \"lightblue\")\nplot_grid(p1, p2, labels = c(\"A\", \"B\"), ncol = 2)\n```\n\n::: {.cell-output-display}\n![](08_Interactions_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nWe see that old suburbs tend to have higher `lstat` and `crim` values compared to new suburbs. This suggests that controlling for these variables is important when examining the relationship between `medv`, `chas`, and `old`.\n\n### Two-Way ANOVA Mathematical Formulation\n\nWe now conduct a two-way ANOVA to formally compare the two models `mod_bb` and `mod_bb2`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(mod_bb, mod_bb2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: medv ~ chas * old\nModel 2: medv ~ chas * old + lstat + crim\n  Res.Df   RSS Df Sum of Sq      F    Pr(>F)    \n1    502 37161                                  \n2    500 18200  2     18961 260.45 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n::: {.step-list}\n1. State the null and alternative hypotheses.\n   $$\n   \\begin{aligned}\n   H_0 &: \\beta_4 = 0 \\text{ and } \\beta_5 = 0 \\\\\n   H_1 &: \\beta_4 \\ne 0 \\text{ or } \\beta_5 \\ne 0\n   \\end{aligned}\n   $$\n   \n   In plain language:\n   - $H_0$: The additional variables `lstat` and `crim` do not improve the model fit.\n   - $H_a$: At least one of the additional variables `lstat` or `crim` improves the model fit.\n\n2. Calculate the F-statistic.\n   \n   The F-statistic is based on the $R^2$ of the two regressions:\n   $$\n   F = \\left(\\frac{n - k_U -1}{p}\\right) \\left(\\frac{R_U^2-R_R^2}{1-R_U^2}\\right) \\sim F(p, n-k_U-1) .\n   $$\n   \n   where\n   - $n = 506$ is the number of observations;\n   - $k_U = 5$ is the number of predictors in the unrestricted model (where $H_1$ is allowed to be true), excluding the intercept;\n   - $p = 2$ is the number of restrictions (i.e., the number of additional variables in the unrestricted model);\n   - $R_U^2 = 0.574$ is the $R^2$ of the unrestricted model;\n   - $R_R^2 = 0.130$ is the $R^2$ of the restricted model.\n\n   Plug in the numbers, we get\n   $$\n   F = \\left(\\frac{506-5-1}{2}\\right) \\left(\\frac{0.574-0.130}{1-0.574}\\right) = 260.56\n   $$\n\n3. Find the critical value\n   \n   The F-statistic follows an $F(2, 502)$ distribution under the null hypothesis. At 5% significance level, we use the the critical value $F_{2,\\infty}=3.00.$\n\n4. Decision rule.\n   \n   Since the calculated F-statistic ($260.56$) is much larger than the critical value ($3.00$), we reject the null hypothesis.\n   \n   This suggests that at least one of `lstat` and `crim` significantly improves the model fit.\n5. Conclusion.\n   \n   We conclude that model (2) with additional control variables `lstat` and `crim` provides a significantly better fit to the data compared to model (1) without these controls.\n:::\n\n\n\n\n## Interactions of a Binary Variable and a Continuous Variable\n\nAn interaction between a binary variable and a continuous variable shows how the effect of the continuous variable changes depending on the group. This helps us see differences that a simple line wouldnâ€™t capture. For example, the effect of business area on house prices might be different in new versus old suburbs.\n\nNow consider the regression model\n\n$$\nmedv_i = \\beta_0 + \\beta_1 \\times indus_i + \\beta_2 \\times old_i + \\beta_3 \\times (indus_i\\times old_i) + u_i\n$$\n\nwhere $indus_i$ being the proportion of non-retail business acres in suburb $i$; $old_i$ is the same binary variable as defined above, indicating if the suburb is new.\n\n**Instructions:**\n\n- Estimate the above regression model and assign the result to `mod_bc`.\n- What is the relationship between `medv` and `indus` for new suburbs? What about old suburbs?\n- Is the effect of `indus` on `medv` statistically different between new and old suburbs? \n- Plot `medv` against `indus` and add the regression lines for both states of the binary variable `old`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_bc <- lm(medv ~ indus * old, data = Boston)\nsummary(mod_bc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = medv ~ indus * old, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-12.379  -5.066  -1.588   3.015  33.046 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 30.06350    0.72882  41.250   <2e-16 ***\nindus       -0.65844    0.06569 -10.024   <2e-16 ***\nold         -7.48438    3.07918  -2.431   0.0154 *  \nindus:old    0.37115    0.17558   2.114   0.0350 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.024 on 502 degrees of freedom\nMultiple R-squared:  0.2434,\tAdjusted R-squared:  0.2389 \nF-statistic: 53.83 on 3 and 502 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\nThe estimated regression model is given by\n\n$$\n\\widehat{medv}_i = 30.06 - 0.66 \\times indus_i - 7.48 \\times old_i + 0.37 \\times (indus_i \\cdot old_i)\n$$\n\n<span class=\"env-green\">**Interpretation of the coefficients**</span>\n\n- For new suburbs (i.e., `old = 0`), the relationship between `medv` and `indus` is given by\n\n  $$\n  E(medv_i | old_i = 0) = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\times indus_i = 30.06 - 0.66 \\times indus_i\n  $$\n\n  Thus, for new suburbs, a one-unit increase in `indus` is associated with a decrease in the expected value of `medv` by 0.66.\n\n- For old suburbs (i.e., `old = 1`), the relationship between `medv` and `indus` is given by\n  \n  $$\n  \\begin{split}\n  E(medv_i | old_i = 1) &= (\\hat{\\beta}_0 + \\hat{\\beta}_2) + (\\hat{\\beta}_1 + \\hat{\\beta}_3) \\times indus_i \\\\\n  &= (30.06 - 7.48) + (-0.66 + 0.37) \\times indus_i \\\\\n  &= 22.58 - 0.29 \\times indus_i\n  \\end{split}\n  $$\n\n  Thus, for old suburbs, a one-unit increase in `indus` is associated with a decrease in the expected value of `medv` by 0.29. The negative effect is smaller in old suburbs due to the positive interaction term ($\\hat{\\beta}_3 = 0.37$).\n\n- The effect of `indus` on `medv` is statistically different between new and old suburbs at 5% significance level given that the coefficient of the interaction term ($\\hat{\\beta}_3$) is statistically significant.\n\n**Visualization**\n\nNow we plot `medv` against `indus` with regression lines for both states of the binary variable `old`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(Boston, aes(x = indus, y = medv, color = factor(old))) +\n    geom_point(alpha = 0.6) +\n    geom_smooth(method = \"lm\", formula = y ~ x, se = FALSE) +\n    labs(\n        x = \"Proportion of Non-Retail Business Acres (indus)\",\n        y = \"Median Home Value (medv)\",\n        color = \"Old Suburb (old)\"\n    ) +\n    scale_color_manual(values = c(\"0\" = \"blue\", \"1\" = \"red\"), labels = c(\"New Suburb\", \"Old Suburb\")) +\n    theme_minimal(base_size = 14) +\n    theme(\n        legend.title = element_blank(),\n        legend.text = element_text(size = 14),\n        legend.position = c(0.8, 0.9)\n    )\n```\n\n::: {.cell-output-display}\n![](08_Interactions_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nWe see that the slope of the regression line for new suburbs (blue) is steeper than that for old suburbs (red), indicating a stronger negative relationship between `medv` and `indus` in new suburbs compared to old suburbs. This visual representation aligns with our earlier interpretation of the regression coefficients.",
    "supporting": [
      "08_Interactions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}